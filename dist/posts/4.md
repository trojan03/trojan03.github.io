## Callibrating Intel RealSense d435 with OpenCV2 and ROS
This tutorial covers how to calibrate the Intel Realsense camera, [model d435](https://click.intel.com/intelr-realsensetm-depth-camera-d435.html) using
ROS and OpenCV Python.

### Prerequisites
Assuming you have Ubuntu 16.04, following applications must be installed in order that everything works:
- OpenCV2. You can refer for example to [this](https://gist.github.com/arthurbeggs/06df46af94af7f261513934e56103b30) tutorial.
- OpenCV-Python
```bash
sudo apt-get install python-opencv
```
- [ROS Kinetic](http://wiki.ros.org/kinetic/Installation/Ubuntu) for Ubuntu 16.04.

### Installing RealSense
1. Install the [drivers](https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md#installing-the-packages).
2. Download the RealSense repository from [here](https://github.com/intel-ros/realsense/releases) and extract it to your ROS workspace.
3. Build the package
```bash
catkin_make clean
catkin_make -DCATKIN_ENABLE_TESTING=False -DCMAKE_BUILD_TYPE=Release
catkin_make install
echo "source path_to_workspace/devel/setup.bash" >> ~/.bashrc
source ~/.bashrc
```

### Testing the camera
Connect the RealSense camera via USB and run the demo launch file
```bash
roslaunch realsense2_camera demo_pointcloud.launch
```
This command will open rviz where you will see the point clouds from the camera  comming from the topic
`/camera/depth/color/points`.

![rviz](/dist/posts/images/3_rviz.png "90%x40%")

### Calibrating the camera using OpenCV2-Python
The following codebase is an adapted version of [this](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html) tutorial from OpenCV.
```python
import numpy as np
import cv2
import glob

# termination criteria
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# prepare object points for a 8x6 chess board
objp = np.zeros((6*8,3), np.float32)
objp[:,:2] = np.mgrid[0:8,0:6].T.reshape(-1,2)

# Arrays to store object points and image points from all the images.
objpoints = [] # 3d point in real world space
imgpoints = [] # 2d points in image plane.

images = glob.glob('/path_to_images/*.png')

for fname in images:
    img = cv2.imread(fname)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    # Find the chess board corners
    ret, corners = cv2.findChessboardCorners(gray, (8,6),None)

    # If found, add object points, image points (after refining them)
    if ret == True:
        objpoints.append(objp)

        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)
        imgpoints.append(corners2)

        # Draw and display the corners
        img = cv2.drawChessboardCorners(img, (8,6), corners2,ret)
        cv2.imshow('img',img)
        cv2.waitKey(500)

cv2.destroyAllWindows()

ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)
np.save('/path_to_images/calibration', [mtx, dist, rvecs, tvecs])
```
Before executing the script, you will need to get the images from the camera with capturing the chess board (8x6 in
  our example).
See e.g. this [link](http://wiki.ros.org/image_view) for more information. We will need at least 10 images for
calibration. Once you have the images, execute the provided script. After executing, you will see the images
with the detected corners on it.

![Chess table](/dist/posts/images/3_chess_table.png "40%x40%")

Once the script is done, it will save the calibration data into the file
`calibration.npy`. To reuse this data, use the following script:
```python
calibration_data = np.load('path_to_images/calibration.npy')
mtx = calibration_data[0]
dist = calibration_data[1]
rvecs = calibration_data[2]
tvecs = calibration_data[3]
```
### Conclusion
We have seen how to calibrate the RealSense camera using OpenCV2 and ROS. In the next post, we will figure out
how to use the RealSense camera to detect the [aruco markers](https://docs.opencv.org/3.4/d5/dae/tutorial_aruco_detection.html) using Python.
